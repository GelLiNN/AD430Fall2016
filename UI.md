##UI Requirements:  
###Main Windows

####Signup/Login Page
* Allow users to sign in with microsoft account, or create a microsoft account, then proceed to Main Page.

####Main Page (Hard of Hearing)
* Has 3 buttons (NLP, Video, Physical)
* Clicking video button starts a video request
* Clicking video button takes users to request page
* Clicking physical button takes users to physical request page
* Clicking NLP button takes user to the NLP chat window

####Main Page (Interpreter)
* Has 2 check boxes with buttons
* Video butten toggles the indicator for video interpretation
* Physical button toggles the indicator for physical interpretation
* When video indicator is on, then interpreter user will be available to HOH users for video
* When video indicator is off, then interpreter user will **not** be available to HOH users for video
* When physical indicator is off, then interpreter user will be available to HOH users for physical interpretation
* When physical indicator is off, then interpreter user will **not** be available to HOH users for physical interpretation
* If user closes app. The indicators are still respected, and they be avaible based on indicators.

####NLP chat page will support Google Voice TTS, keyboard, and scrolling conversation history

####Physical Requests Page where Hard of Hearing people will select a radius for interpreters, and tap a "make request" button.

###4 push notifications:

* New Video Request for interpreter => accept/deny buttons  
* Video request accepted for Hard of Hearing user => start button  
* New Physical Request for interpreter => accept/deny buttons  
* Physical Interpreter on the way (no buttons necessary
